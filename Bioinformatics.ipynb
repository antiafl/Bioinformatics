{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de tumores sobre datos de expresión génica obtenidos por RNA-Seq con técnicas de aprendizaje máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este trabajo se plantea la utilización de diversas técnicas de aprendizaje automático con el fin de resolver un problema de clasificación que permita etiquetar distintos tipos de tumores en función de valores de expresión de diversos genes obtenidos por medio de la técnica de RNA-Seq en numerosos pacientes. Dada la enorme cantidad de atributos de los datos de entrada, en primer lugar es necesario un preprocesamiento de la información para más tarde poder entrenar distintos tipos de modelos (en este caso: algoritmo kNN, máquina de soporte vectorial y random forest). Los resultados muestran que los datos se pueden procesar y clasificar de forma satisfactoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente trabajo, de temática biomédica, se fundamenta en la utilización de diversas técnicas de aprendizaje automático (también nombrado con su término anglosajón, *machine learning*, de ahora en adelante) para la consecución de un problema de clasificación. Para ello se dispone de una base de datos procedente del repositorio \"UCI Machine Learning\" denominada **gene expression cancer RNA-Seq Data Set** (disponible en la siguiente URL https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#). Esta, contiene instancias de niveles de expresión génica extraídos utilizando la técnica RNA-Seq por medio de la plataforma Illumina HiSeq. La base de datos en cuestión dispone de 801 instancias (una por cada paciente analizado) donde, a su vez, cada una de las instancias está definida por 20531 atributos (uno por cada gen sobre el que se analiza su nivel de expresión). Por su parte, las salidas deseadas se pueden etiquetar en las siguientes cinco clases:\n",
    "\n",
    "- **BRCA**, **Br**east **Ca**ncer, del cual se dispone de 136 instancias.\n",
    "- **KIRC**, **Ki**dney **R**enal Cell **C**arcinoma, del cual se dispone de 141 instancias.\n",
    "- **COAD**, **Co**lon **Ad**enocarcinoma, del cual se dispone de 78 instancias.\n",
    "- **LUAD**, **Lu**ng **Ad**enocarcinoma, del cual se dispone de 146 instancias.\n",
    "- **PRAD**, **Pr**ostate **Ad**enocarcinoma, del cual se dispone de 300 instancias.\n",
    "\n",
    "La ingente cantidad de información disponible para cada instancia y el carácter multiclase del problema, convierten en idóneo a este caso para la aplicación de las técnicas de aprendizaje máquina. Adicionalmente, se puede observar un desbalanceo entre el número de patrones que pertenecen a cada clase, lo cual resulta relevante a la hora de presentar los resultados. \n",
    "\n",
    "El dataset empleado está formado por dos ficheros. El primero de ellos es \"data.csv\" que contiene los datos de entrada al modelo donde las filas representan a cada una de las instancias y las columnas, sus correspondientes más de 20000 atributos (de aproximadamente 200 MB de tamaño). Por su parte, el fichero \"labels.csv\" contiene las correspondientes etiquetas de salida para cada uno de los patrones, es decir, a cuál de las cinco clases contempladas en el problema original pertenece. En la descripción del dataset dada por el repositorio, los genes presentes en \"data.csv\" son nombrados con una nomenclatura \"dummy\" por simplicidad, pero mantienen el orden de los nombres originales. A modo de resumen de las características del dataset, se adjunta la tabla que se provee en la propia página del repositorio.\n",
    "\n",
    "<img src=\"./images/dataset_description.png\">\n",
    "\n",
    "Para presentar todos los pasos llevados a cabo con la intención de resolver el problema planteado, este documento presenta una sección de *Metodología*, donde se presentan tanto los pasos llevados a cabo para el entrenamiento de los modelos como los pasos previos. A continuación, en una sección de *Resultados y discusión* se presentarán los resultados obtenidos y una discusión sobre los mismos, estableciendo comparaciones entre diferentes aspectos a tener en cuenta. Finalmente, una sección de *Conclusiones* y otra de *Trabajo futuro*, donde se exponen las posibles líneas a seguir en posteriores aproximaciones al problema, concluyen la redacción de este documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se enumerarán los pasos a llevar a cabo, para más tarde describir cada uno de ellos de forma más precisa.\n",
    "\n",
    "- En primer lugar, para abordar el problema planteado, es necesario preprocesar los datos que provienen del dataset. Dado que el número de atributos es inmanejable de forma manual, primeramente es indispensable reducir la dimensionalidad de los datos además de aplicar una normalización de los mismos para favorecer el proceso de aprendizaje de los modelos. Una vez hecho, se procede a entrenar los modelos para más tarde poder evaluar su efectividad. Esto se describe con más detalle en la sección de *Lectura y preprocesamiento de los datos* que se muestra a continuación.\n",
    "\n",
    "- En segundo lugar, una vez que los datos son correctamente procesados, se puede proceder a entrenar los modelos propuestos, obteniendo más tarde sus correspondientes resultados. Esto se describe con gran detalle en la sección *Entrenamiento de los modelos*.\n",
    "\n",
    "Cabe destacar que el principal foco de este trabajo es observar la influencia del número de atributos obtenidos al aplicar las técnicas de preprocesamiento sobre la efectividad de los modelos. Por otra parte, se han seleccionado diferentes modelos de aprendizaje para estudiar la viabilidad de resolución del problema bajo diversos puntos de vista. Sin embargo, no se pretende realizar un fine-tuning de los parámetros de dichos modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura y preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dado que el número de atributos es inmanejable de forma manual (20531), primeramente es indispensable reducir la dimensionalidad de los datos además de aplicar una normalización de los mismos para favorecer el proceso de aprendizaje de los modelos. \n",
    "\n",
    "- Para la reducción de la dimensionalidad, se contemplan dos opciones: utilizar algunas técnicas manuales como *features selection* o *features extraction* o bien la técnica estadística del *Principal Components Analysis* o *PCA*. Puesto que seleccionar un número determinado de atributos de entre los más de 20000 es súmamente complejo, consideramos que la técnica de PCA es mucho más adecuada para este problema concreto.\n",
    "\n",
    "- Por otra parte, es necesario normalizar los datos de entrada para favorecer la tarea de aprendizaje por parte de los modelos. Para ello, se realiza una estandarización de los mismos en dos ocasiones: la primera, previa a la PCA y, la segunda, posterior a la aplicación de la misma (puesto que PCA podría desnormalizar los datos a la salida). \n",
    "\n",
    "- **Para realizar la normalización y la PCA, se dispone del script \"read_data.py\" en el directorio de este proyecto. Los ficheros \"data.csv\" y \"labels.csv\", es decir, los que contienen la información original que proporciona la base de datos de UCI Machine Learning, no se incluyen en este directorio al ocupar más de 200 MB y suponer una carga excesiva sobre el repositorio de GitHub utilizado para albergar los archivos de este trabajo. Para acceder a los mismos, pueden descargarse directamente desde la página de UCI Machine Learning.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez los datos son convenientemente preprocesados, se procede a entrenar los tres modelos de aprendizaje máquina que se han seleccionado: algoritmo kNN, máquina de soporte vectorial y random forest. Dichos modelos han sido escogidos considerando su gran uso en inteligencia artificial para la resolución de problemas de clasificación y la adecuación que estos tienen a dichos problemas, por lo general. Para proceder al entrenamiento, es necesario realizar un splitting, es decir, en este caso concreto, dividir el conjunto de datos original en dos subconjuntos: el conjunto de entrenamiento y el conjunto de test. El splitting seleccionado para esta aproximación es de tipo aleatorio y con una repartición del 60%-40% para entrenamiento y test, respectivamente. Considerando ese elemento aleatorio, es necesario repetir la acción un número N de veces significativo. Sobre cada uno de los entrenamientos, se obtienen los valores de una serie de métricas. \n",
    "\n",
    "Posteriormente, para conseguir una métrica representativa de tal cantidad de entrenamientos, múltiples estadísticos son computados (en este caso, la media, para tener un valor concreto de la métrica y la desviación típica, para conocer la robustez de los modelos). Del mismo modo, es necesario escoger qué clase de métricas se desean utilizar para evaluar.\n",
    "\n",
    "Cabe destacar, nuevamente, que el problema a tratar es de tipo multiclase y que posee concretamente cinco posibles etiquetas cuya descripción se expone en la sección de *Introducción*.\n",
    "\n",
    "A modo de resumen, a continuación se exponen de forma breve los pasos a seguir:\n",
    "\n",
    "- Selección del modelo a utilizar.\n",
    "- Entrenamiento N veces de los modelos concretos realizando un splitting aleatorio diferente en cada una de las iteraciones del bucle.\n",
    "- Registrar las métricas de bondad en cada uno de los ciclos del proceso de entrenamiento.\n",
    "- Computar los estadísticos sobre los resultados obtenidos y así disponer de valores representativos para los N entrenamientos.\n",
    "\n",
    "A continuación, se adjunta el código correspondiente a los scripts de entrenamiento de cada uno de los modelos utilizados. Por defecto, se utiliza en todos los casos una PCA de 10 atributos como entrada. Debe tenerse en cuenta que los resultados obtenidos no serán exactamente iguales si no similares a los aquí mostrados, por consecuencia de la componente aleatoria del splitting utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo kNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%file train_kNN.py\n",
    "\n",
    "import argparse\n",
    "from sklearn.neighbors import KNeighborsClassifier as knc\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# En esta función se obtiene la matriz correspondiente al fichero .csv que\n",
    "# se le pase como parámetro.\n",
    "def get_data(filename):\n",
    "    matrix = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            matrix.append(row)\n",
    "\n",
    "    return np.array(matrix)\n",
    "\n",
    "def store_metrics(precision, sensivity, auc_roc, auc_pr, path):\n",
    "    with open(path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['', 'Global', '0', '1', '2', '3', '4'])\n",
    "        writer.writerow(['Precisión', precision, '', '', '', '', ''])\n",
    "        writer.writerow(['Sensibilidad', '', sensivity[0], sensivity[1], \\\n",
    "                                    sensivity[2], sensivity[3], sensivity[4]])\n",
    "        writer.writerow(['AUC-ROC', '', auc_roc[0], auc_roc[1], \\\n",
    "                                    auc_roc[2], auc_roc[3], auc_roc[4]])\n",
    "        writer.writerow(['AUC-PR', '', auc_pr[0], auc_pr[1], \\\n",
    "                                    auc_pr[2], auc_pr[3], auc_pr[4]])\n",
    "\n",
    "# Esta función se utiliza para convertir los vectores de la matriz target en\n",
    "# un número entero.\n",
    "def convert_vector_to_number(target_vector):\n",
    "    if (target_vector[0]==1):\n",
    "        output_value = 0\n",
    "    if (target_vector[1]==1):\n",
    "        output_value = 1\n",
    "    if (target_vector[2]==1):\n",
    "        output_value = 2\n",
    "    if (target_vector[3]==1):\n",
    "        output_value = 3\n",
    "    if (target_vector[4]==1):\n",
    "        output_value = 4\n",
    "\n",
    "    return output_value\n",
    "\n",
    "# Esta función se utiliza para convertir un número entero representativo de un\n",
    "# tag en un vector.\n",
    "def convert_number_to_vector(values):\n",
    "    vectors = []\n",
    "    for target_value in values:\n",
    "        if (target_value==0):\n",
    "            output_value = [1, 0, 0, 0, 0]\n",
    "        if (target_value==1):\n",
    "            output_value = [0, 1, 0, 0, 0]\n",
    "        if (target_value==2):\n",
    "            output_value = [0, 0, 1, 0, 0]\n",
    "        if (target_value==3):\n",
    "            output_value = [0, 0, 0, 1, 0]\n",
    "        if (target_value==4):\n",
    "            output_value = [0, 0, 0, 0, 1]\n",
    "        vectors.append(output_value)\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def process_targets(target_data):\n",
    "    target_size = np.shape(target_data)\n",
    "\n",
    "    final_targets = []\n",
    "    for row in range(0, target_size[0]):\n",
    "        final_targets.append(convert_vector_to_number(target_data[row, :]))\n",
    "\n",
    "    return final_targets\n",
    "\n",
    "def calculate_precision(conf_matrix, num_of_classes):\n",
    "    precision = 0.0\n",
    "    for aux_class in range(0, num_of_classes):\n",
    "        precision+=conf_matrix[aux_class, aux_class]\n",
    "    precision/=np.sum(conf_matrix)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def calculate_sensivity(conf_matrix, selected_class):\n",
    "    sensivity = 0.0\n",
    "    sensivity = conf_matrix[selected_class, selected_class]/np.sum(conf_matrix[selected_class])\n",
    "\n",
    "    return sensivity\n",
    "\n",
    "def calculate_auc_roc(targets, outputs):\n",
    "    fpr, tpr, _ = roc_curve(targets, outputs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def calculate_auc_pr(targets, outputs):\n",
    "    pr_auc = average_precision_score(targets, outputs)\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "def show_roc_curve():\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = 5\n",
    "\n",
    "    plt.figure()\n",
    "    colours = ['red', 'green', 'orange', 'brown', 'black']\n",
    "    for it in range(0, n_classes):\n",
    "        fpr[it], tpr[it], _ = roc_curve(target[:, it], decision[:, it])\n",
    "        roc_auc[it] = auc(fpr[it], tpr[it])\n",
    "        plt.plot(fpr[it], tpr[it], color=colours[it])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def main(args):\n",
    "    input_data = get_data(args.inputs_file).astype(float)\n",
    "    target_data = get_data(args.targets_file).astype(int)\n",
    "\n",
    "    classifier = knc(n_neighbors=3, algorithm='ball_tree')\n",
    "    target_data = process_targets(target_data)\n",
    "    noftrains = args.noftrains\n",
    "    classes = 5\n",
    "    chosen_test_size = args.test_size\n",
    "\n",
    "    precision_list = []\n",
    "    sensivity_list = []\n",
    "    auc_roc_list = []\n",
    "    auc_pr_list = []\n",
    "    best_precision = -1\n",
    "    model_filename = '%s/%s_kNN.pth'%(args.models_path, \\\n",
    "                                args.inputs_file.replace('.csv', ''))\n",
    "    for it in range(0, noftrains):\n",
    "        # Separación aleatoria de los conjuntos de entrenamiento y test.\n",
    "        train_input, test_input, train_output, test_output = \\\n",
    "            train_test_split(input_data, target_data, test_size=chosen_test_size)\n",
    "        classifier.fit(train_input, train_output)\n",
    "        prediction = classifier.predict(test_input)\n",
    "        decision = classifier.predict_proba(test_input)\n",
    "        conf_matrix = confusion_matrix(test_output, prediction)\n",
    "        precision = calculate_precision(conf_matrix, classes)*100\n",
    "        precision_list.append(precision)\n",
    "        sensivity = []\n",
    "        auc_roc = []\n",
    "        auc_pr = []\n",
    "        for class_selected in range(0, classes):\n",
    "            sensivity.append(calculate_sensivity(conf_matrix, class_selected)*100)\n",
    "            output_vectors = np.array(convert_number_to_vector(test_output))\n",
    "            prediction_vectors = np.array(convert_number_to_vector(prediction))\n",
    "            auc_roc.append(calculate_auc_roc(output_vectors[:, class_selected], \\\n",
    "                                        prediction_vectors[:, class_selected])*100)\n",
    "            auc_pr.append(calculate_auc_pr(output_vectors[:, class_selected], \\\n",
    "                                        prediction_vectors[:, class_selected])*100)\n",
    "        sensivity_list.append(sensivity)\n",
    "        auc_roc_list.append(auc_roc)\n",
    "        auc_pr_list.append(auc_pr)\n",
    "\n",
    "        if (precision>best_precision):\n",
    "            best_precision = precision\n",
    "            pickle.dump(classifier, open(model_filename, 'wb'))\n",
    "\n",
    "    precision_string = '%.4f +- %.4f'%(np.mean(precision_list), \\\n",
    "                                                    np.std(precision_list))\n",
    "    sensivity_string_list = []\n",
    "    auc_roc_string_list = []\n",
    "    auc_pr_string_list = []\n",
    "    for class_selected in range(0, classes):\n",
    "        sensivity_string = '%.4f +- %.4f'%(np.mean(sensivity_list[class_selected]),\n",
    "                                                                    np.std(sensivity_list[class_selected]))\n",
    "        sensivity_string_list.append(sensivity_string)\n",
    "        auc_roc_string = '%.4f +- %.4f'%(np.mean(auc_roc_list[class_selected]), \\\n",
    "                                            np.std(auc_roc_list[class_selected]))\n",
    "        auc_roc_string_list.append(auc_roc_string)\n",
    "        auc_pr_string = '%.4f +- %.4f\\n'%(np.mean(auc_pr_list[class_selected]), \\\n",
    "                                            np.std(auc_pr_list[class_selected]))\n",
    "        auc_pr_string_list.append(auc_pr_string)\n",
    "\n",
    "    results_path = '%s/results_kNN_%s'%(args.results_path, args.inputs_file)\n",
    "    store_metrics(precision_string, sensivity_string_list, auc_roc_string_list, \\\n",
    "                    auc_pr_string_list, results_path)\n",
    "    print('Results were stored at %s'%results_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Código de la práctica de bioinformática')\n",
    "    parser.add_argument('--inputs_file', type=str)\n",
    "    parser.add_argument('--targets_file', type=str)\n",
    "    parser.add_argument('--noftrains', type=int)\n",
    "    parser.add_argument('--test_size', type=float)\n",
    "    parser.add_argument('--results_path', type=str)\n",
    "    parser.add_argument('--models_path', type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, se utiliza como entrada una PCA de 10 atributos (el fichero de entrada al modelo viene especificado en el argumento \"--inputs_file\" y el de salidas esperadas por \"--targets_file\"), se entrenan 100 modelos diferentes (especificado por el argumento \"--noftrains\"), se utiliza un splitting con 40% de patrones para test (especificado por el argumento \"--test_size\". Todo lo restante se destina a entrenamiento) y los resultados se almacenan en un .csv en la ruta especificada por \"--results_path\". El modelo con la mejor precisión se almacena en la especificada por \"--models_path\".\n",
    "\n",
    "- Nombre del fichero de resultados = results_kNN_**inputs_PCA_10**.csv\n",
    "\n",
    "- Nombre del fichero con el modelo de mejor precisión = **inputs_PCA_10**_kNN.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train_kNN.py --inputs_file inputs_PCA_10.csv --targets_file targets.csv --noftrains 100 --test_size=0.4 --results_path ./results --models_path=./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Máquinas de soporte vectorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%file train_svm.py\n",
    "\n",
    "import argparse\n",
    "from sklearn import svm\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# En esta función se obtiene la matriz correspondiente al fichero .csv que\n",
    "# se le pase como parámetro.\n",
    "def get_data(filename):\n",
    "    matrix = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            matrix.append(row)\n",
    "\n",
    "    return np.array(matrix)\n",
    "\n",
    "def store_metrics(precision, sensivity, auc_roc, auc_pr, path):\n",
    "    with open(path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['', 'Global', '0', '1', '2', '3', '4'])\n",
    "        writer.writerow(['Precisión', precision, '', '', '', '', ''])\n",
    "        writer.writerow(['Sensibilidad', '', sensivity[0], sensivity[1], \\\n",
    "                                    sensivity[2], sensivity[3], sensivity[4]])\n",
    "        writer.writerow(['AUC-ROC', '', auc_roc[0], auc_roc[1], \\\n",
    "                                    auc_roc[2], auc_roc[3], auc_roc[4]])\n",
    "        writer.writerow(['AUC-PR', '', auc_pr[0], auc_pr[1], \\\n",
    "                                    auc_pr[2], auc_pr[3], auc_pr[4]])\n",
    "\n",
    "# Esta función se utiliza para convertir los vectores de la matriz target en\n",
    "# un número entero.\n",
    "def convert_vector_to_number(target_vector):\n",
    "    if (target_vector[0]==1):\n",
    "        output_value = 0\n",
    "    if (target_vector[1]==1):\n",
    "        output_value = 1\n",
    "    if (target_vector[2]==1):\n",
    "        output_value = 2\n",
    "    if (target_vector[3]==1):\n",
    "        output_value = 3\n",
    "    if (target_vector[4]==1):\n",
    "        output_value = 4\n",
    "\n",
    "    return output_value\n",
    "\n",
    "# Esta función se utiliza para convertir un número entero representativo de un\n",
    "# tag en un vector.\n",
    "def convert_number_to_vector(values):\n",
    "    vectors = []\n",
    "    for target_value in values:\n",
    "        if (target_value==0):\n",
    "            output_value = [1, 0, 0, 0, 0]\n",
    "        if (target_value==1):\n",
    "            output_value = [0, 1, 0, 0, 0]\n",
    "        if (target_value==2):\n",
    "            output_value = [0, 0, 1, 0, 0]\n",
    "        if (target_value==3):\n",
    "            output_value = [0, 0, 0, 1, 0]\n",
    "        if (target_value==4):\n",
    "            output_value = [0, 0, 0, 0, 1]\n",
    "        vectors.append(output_value)\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def process_targets(target_data):\n",
    "    target_size = np.shape(target_data)\n",
    "\n",
    "    final_targets = []\n",
    "    for row in range(0, target_size[0]):\n",
    "        final_targets.append(convert_vector_to_number(target_data[row, :]))\n",
    "\n",
    "    return final_targets\n",
    "\n",
    "def calculate_precision(conf_matrix, num_of_classes):\n",
    "    precision = 0.0\n",
    "    for aux_class in range(0, num_of_classes):\n",
    "        precision+=conf_matrix[aux_class, aux_class]\n",
    "    precision/=np.sum(conf_matrix)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def calculate_sensivity(conf_matrix, selected_class):\n",
    "    sensivity = 0.0\n",
    "    sensivity = conf_matrix[selected_class, selected_class]/np.sum(conf_matrix[selected_class])\n",
    "\n",
    "    return sensivity\n",
    "\n",
    "def calculate_auc_roc(targets, outputs):\n",
    "    fpr, tpr, _ = roc_curve(targets, outputs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def calculate_auc_pr(targets, outputs):\n",
    "    pr_auc = average_precision_score(targets, outputs)\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "def show_roc_curve():\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = 5\n",
    "\n",
    "    plt.figure()\n",
    "    colours = ['red', 'green', 'orange', 'brown', 'black']\n",
    "    for it in range(0, n_classes):\n",
    "        fpr[it], tpr[it], _ = roc_curve(target[:, it], decision[:, it])\n",
    "        roc_auc[it] = auc(fpr[it], tpr[it])\n",
    "        plt.plot(fpr[it], tpr[it], color=colours[it])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def main(args):\n",
    "    input_data = get_data(args.inputs_file).astype(float)\n",
    "    target_data = get_data(args.targets_file).astype(int)\n",
    "\n",
    "    classifier = svm.SVC()\n",
    "    target_data = process_targets(target_data)\n",
    "    noftrains = args.noftrains\n",
    "    classes = 5\n",
    "    chosen_test_size = args.test_size\n",
    "\n",
    "    precision_list = []\n",
    "    sensivity_list = []\n",
    "    auc_roc_list = []\n",
    "    auc_pr_list = []\n",
    "    best_precision = -1\n",
    "    model_filename = '%s/%s_svm.pth'%(args.models_path, \\\n",
    "                                args.inputs_file.replace('.csv', ''))\n",
    "    for it in range(0, noftrains):\n",
    "        # Separación aleatoria de los conjuntos de entrenamiento y test.\n",
    "        train_input, test_input, train_output, test_output = \\\n",
    "            train_test_split(input_data, target_data, test_size=chosen_test_size)\n",
    "        classifier.fit(train_input, train_output)\n",
    "        prediction = classifier.predict(test_input)\n",
    "        decision = classifier.decision_function(test_input)\n",
    "        conf_matrix = confusion_matrix(test_output, prediction)\n",
    "        precision = calculate_precision(conf_matrix, classes)*100\n",
    "        precision_list.append(precision)\n",
    "        sensivity = []\n",
    "        auc_roc = []\n",
    "        auc_pr = []\n",
    "        for class_selected in range(0, classes):\n",
    "            sensivity.append(calculate_sensivity(conf_matrix, class_selected)*100)\n",
    "            output_vectors = np.array(convert_number_to_vector(test_output))\n",
    "            prediction_vectors = np.array(convert_number_to_vector(prediction))\n",
    "            auc_roc.append(calculate_auc_roc(output_vectors[:, class_selected], \\\n",
    "                                        prediction_vectors[:, class_selected])*100)\n",
    "            auc_pr.append(calculate_auc_pr(output_vectors[:, class_selected], \\\n",
    "                                        prediction_vectors[:, class_selected])*100)\n",
    "        sensivity_list.append(sensivity)\n",
    "        auc_roc_list.append(auc_roc)\n",
    "        auc_pr_list.append(auc_pr)\n",
    "\n",
    "        if (precision>best_precision):\n",
    "            best_precision = precision\n",
    "            pickle.dump(classifier, open(model_filename, 'wb'))\n",
    "\n",
    "    precision_string = '%.4f +- %.4f'%(np.mean(precision_list), \\\n",
    "                                                    np.std(precision_list))\n",
    "    sensivity_string_list = []\n",
    "    auc_roc_string_list = []\n",
    "    auc_pr_string_list = []\n",
    "    for class_selected in range(0, classes):\n",
    "        sensivity_string = '%.4f +- %.4f'%(np.mean(sensivity_list[class_selected]),\n",
    "                                                                    np.std(sensivity_list[class_selected]))\n",
    "        sensivity_string_list.append(sensivity_string)\n",
    "        auc_roc_string = '%.4f +- %.4f'%(np.mean(auc_roc_list[class_selected]), \\\n",
    "                                            np.std(auc_roc_list[class_selected]))\n",
    "        auc_roc_string_list.append(auc_roc_string)\n",
    "        auc_pr_string = '%.4f +- %.4f\\n'%(np.mean(auc_pr_list[class_selected]), \\\n",
    "                                            np.std(auc_pr_list[class_selected]))\n",
    "        auc_pr_string_list.append(auc_pr_string)\n",
    "\n",
    "    results_path = '%s/results_svm_%s'%(args.results_path, args.inputs_file)\n",
    "    store_metrics(precision_string, sensivity_string_list, auc_roc_string_list, \\\n",
    "                    auc_pr_string_list, results_path)\n",
    "    print('Results were stored at %s'%results_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Código de la práctica de bioinformática')\n",
    "    parser.add_argument('--inputs_file', type=str)\n",
    "    parser.add_argument('--targets_file', type=str)\n",
    "    parser.add_argument('--noftrains', type=int)\n",
    "    parser.add_argument('--test_size', type=float)\n",
    "    parser.add_argument('--results_path', type=str)\n",
    "    parser.add_argument('--models_path', type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La utilización de los parámetros es la misma que en el caso del algoritmo kNN.\n",
    "\n",
    "- Nombre del fichero de resultados = results_svm_**inputs_PCA_10**.csv\n",
    "\n",
    "- Nombre del fichero con el modelo de mejor precisión = **inputs_PCA_10**_svm.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train_svm.py --inputs_file inputs_PCA_10.csv --targets_file targets.csv --noftrains 100 --test_size=0.4 --results_path ./results --models_path=./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%file train_rfor.py\n",
    "\n",
    "import argparse\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# En esta función se obtiene la matriz correspondiente al fichero .csv que\n",
    "# se le pase como parámetro.\n",
    "def get_data(filename):\n",
    "    matrix = []\n",
    "    with open(filename) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            matrix.append(row)\n",
    "\n",
    "    return np.array(matrix)\n",
    "\n",
    "def store_metrics(precision, sensivity, auc_roc, auc_pr, path):\n",
    "    with open(path, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['', 'Global', '0', '1', '2', '3', '4'])\n",
    "        writer.writerow(['Precisión', precision, '', '', '', '', ''])\n",
    "        writer.writerow(['Sensibilidad', '', sensivity[0], sensivity[1], \\\n",
    "                                    sensivity[2], sensivity[3], sensivity[4]])\n",
    "        writer.writerow(['AUC-ROC', '', auc_roc[0], auc_roc[1], \\\n",
    "                                    auc_roc[2], auc_roc[3], auc_roc[4]])\n",
    "        writer.writerow(['AUC-PR', '', auc_pr[0], auc_pr[1], \\\n",
    "                                    auc_pr[2], auc_pr[3], auc_pr[4]])\n",
    "\n",
    "# Esta función se utiliza para convertir los vectores de la matriz target en\n",
    "# un número entero.\n",
    "def convert_vector_to_number(target_vector):\n",
    "    if (target_vector[0]==1):\n",
    "        output_value = 0\n",
    "    if (target_vector[1]==1):\n",
    "        output_value = 1\n",
    "    if (target_vector[2]==1):\n",
    "        output_value = 2\n",
    "    if (target_vector[3]==1):\n",
    "        output_value = 3\n",
    "    if (target_vector[4]==1):\n",
    "        output_value = 4\n",
    "\n",
    "    return output_value\n",
    "\n",
    "# Esta función se utiliza para convertir un número entero representativo de un\n",
    "# tag en un vector.\n",
    "def convert_number_to_vector(values):\n",
    "    vectors = []\n",
    "    for target_value in values:\n",
    "        if (target_value==0):\n",
    "            output_value = [1, 0, 0, 0, 0]\n",
    "        if (target_value==1):\n",
    "            output_value = [0, 1, 0, 0, 0]\n",
    "        if (target_value==2):\n",
    "            output_value = [0, 0, 1, 0, 0]\n",
    "        if (target_value==3):\n",
    "            output_value = [0, 0, 0, 1, 0]\n",
    "        if (target_value==4):\n",
    "            output_value = [0, 0, 0, 0, 1]\n",
    "        vectors.append(output_value)\n",
    "\n",
    "    return vectors\n",
    "\n",
    "def process_targets(target_data):\n",
    "    target_size = np.shape(target_data)\n",
    "\n",
    "    final_targets = []\n",
    "    for row in range(0, target_size[0]):\n",
    "        final_targets.append(convert_vector_to_number(target_data[row, :]))\n",
    "\n",
    "    return final_targets\n",
    "\n",
    "def calculate_precision(conf_matrix, num_of_classes):\n",
    "    precision = 0.0\n",
    "    for aux_class in range(0, num_of_classes):\n",
    "        precision+=conf_matrix[aux_class, aux_class]\n",
    "    precision/=np.sum(conf_matrix)\n",
    "\n",
    "    return precision\n",
    "\n",
    "def calculate_sensivity(conf_matrix, selected_class):\n",
    "    sensivity = 0.0\n",
    "    sensivity = conf_matrix[selected_class, selected_class]/np.sum(conf_matrix[selected_class])\n",
    "\n",
    "    return sensivity\n",
    "\n",
    "def calculate_auc_roc(targets, outputs):\n",
    "    fpr, tpr, _ = roc_curve(targets, outputs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def calculate_auc_pr(targets, outputs):\n",
    "    pr_auc = average_precision_score(targets, outputs)\n",
    "\n",
    "    return pr_auc\n",
    "\n",
    "def show_roc_curve():\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = 5\n",
    "\n",
    "    plt.figure()\n",
    "    colours = ['red', 'green', 'orange', 'brown', 'black']\n",
    "    for it in range(0, n_classes):\n",
    "        fpr[it], tpr[it], _ = roc_curve(target[:, it], decision[:, it])\n",
    "        roc_auc[it] = auc(fpr[it], tpr[it])\n",
    "        plt.plot(fpr[it], tpr[it], color=colours[it])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def main(args):\n",
    "    input_data = get_data(args.inputs_file).astype(float)\n",
    "    target_data = get_data(args.targets_file).astype(int)\n",
    "\n",
    "    classifier = rfc(max_depth=4, random_state=0)\n",
    "    target_data = process_targets(target_data)\n",
    "    noftrains = args.noftrains\n",
    "    classes = 5\n",
    "    chosen_test_size = args.test_size\n",
    "\n",
    "    precision_list = []\n",
    "    sensivity_list = []\n",
    "    auc_roc_list = []\n",
    "    auc_pr_list = []\n",
    "    best_precision = -1\n",
    "    model_filename = '%s/%s_rfor.pth'%(args.models_path, \\\n",
    "                                args.inputs_file.replace('.csv', ''))\n",
    "    for it in range(0, noftrains):\n",
    "        # Separación aleatoria de los conjuntos de entrenamiento y test.\n",
    "        train_input, test_input, train_output, test_output = \\\n",
    "            train_test_split(input_data, target_data, test_size=chosen_test_size)\n",
    "        classifier.fit(train_input, train_output)\n",
    "        prediction = classifier.predict(test_input)\n",
    "        decision = classifier.predict_proba(test_input)\n",
    "        conf_matrix = confusion_matrix(test_output, prediction)\n",
    "        precision = calculate_precision(conf_matrix, classes)*100\n",
    "        precision_list.append(precision)\n",
    "        sensivity = []\n",
    "        auc_roc = []\n",
    "        auc_pr = []\n",
    "        for class_selected in range(0, classes):\n",
    "            sensivity.append(calculate_sensivity(conf_matrix, class_selected)*100)\n",
    "            output_vectors = np.array(convert_number_to_vector(test_output))\n",
    "            prediction_vectors = np.array(convert_number_to_vector(prediction))\n",
    "            auc_roc.append(calculate_auc_roc(output_vectors[:, class_selected], \\\n",
    "                                        prediction_vectors[:, class_selected])*100)\n",
    "            auc_pr.append(calculate_auc_pr(output_vectors[:, class_selected], \\\n",
    "                                        prediction_vectors[:, class_selected])*100)\n",
    "        sensivity_list.append(sensivity)\n",
    "        auc_roc_list.append(auc_roc)\n",
    "        auc_pr_list.append(auc_pr)\n",
    "\n",
    "        if (precision>best_precision):\n",
    "            best_precision = precision\n",
    "            pickle.dump(classifier, open(model_filename, 'wb'))\n",
    "\n",
    "    precision_string = '%.4f +- %.4f'%(np.mean(precision_list), \\\n",
    "                                                    np.std(precision_list))\n",
    "    sensivity_string_list = []\n",
    "    auc_roc_string_list = []\n",
    "    auc_pr_string_list = []\n",
    "    for class_selected in range(0, classes):\n",
    "        sensivity_string = '%.4f +- %.4f'%(np.mean(sensivity_list[class_selected]),\n",
    "                                                                    np.std(sensivity_list[class_selected]))\n",
    "        sensivity_string_list.append(sensivity_string)\n",
    "        auc_roc_string = '%.4f +- %.4f'%(np.mean(auc_roc_list[class_selected]), \\\n",
    "                                            np.std(auc_roc_list[class_selected]))\n",
    "        auc_roc_string_list.append(auc_roc_string)\n",
    "        auc_pr_string = '%.4f +- %.4f\\n'%(np.mean(auc_pr_list[class_selected]), \\\n",
    "                                            np.std(auc_pr_list[class_selected]))\n",
    "        auc_pr_string_list.append(auc_pr_string)\n",
    "\n",
    "    results_path = '%s/results_rfor_%s'%(args.results_path, args.inputs_file)\n",
    "    store_metrics(precision_string, sensivity_string_list, auc_roc_string_list, \\\n",
    "                    auc_pr_string_list, results_path)\n",
    "    print('Results were stored at %s'%results_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Código de la práctica de bioinformática')\n",
    "    parser.add_argument('--inputs_file', type=str)\n",
    "    parser.add_argument('--targets_file', type=str)\n",
    "    parser.add_argument('--noftrains', type=int)\n",
    "    parser.add_argument('--test_size', type=float)\n",
    "    parser.add_argument('--results_path', type=str)\n",
    "    parser.add_argument('--models_path', type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La utilización de los parámetros es la misma que en los dos casos anteriores.\n",
    "\n",
    "- Nombre del fichero de resultados = results_rfor_**inputs_PCA_10**.csv\n",
    "\n",
    "- Nombre del fichero con el modelo de mejor precisión = **inputs_PCA_10**_rfor.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train_rfor.py --inputs_file inputs_PCA_10.csv --targets_file targets.csv --noftrains 100 --test_size=0.4 --results_path ./results --models_path=./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados y Discusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se presentan los resultados que se han obtenido con cada uno de los modelos en cuestión. En primer lugar, cabe destacar que los tiempos de ejecución de los experimentos, a pesar de realizarse cada uno N veces, se ejecutan en un tiempo relativamente aceptable. Destacar que, para todos los casos, el número de entrenamientos para el cual se computan los estadísticos deseados (media y desviación y desviación típica) es de 100.\n",
    "\n",
    "### Algoritmo kNN\n",
    "\n",
    "El parámetro usado para este modelo fue *k = 3*, de esta manera considerando los tres vecinos más próximos para realizar la clasificación. Cabe recordar que, al no realizar un fine-tuning de los parámetros que configuran este algoritmo, dicho valor se mantiene constante para todos los entrenamientos realizados. Se ejecutan cuatro experimentos diferentes, aplicando un PCA para obtener, respectivamente, 2, 3, 5 y 10 atributos. La principal característica que se observa es que un número más elevado de atributos comporta un incremento de la bondad de las métricas utilizadas, siendo el caso de 10 atributos el que ofrece unas métricas más aceptables. Como métricas calculadas, se tiene la precisión global, la sensibilidad de cada una de las clases así como la AUC-ROC y la AUC-PR. Sin embargo, a efectos de comparación, se decide utilizar la precisión por ser una métrica global representativa de todas las clases y la AUC-PR que, para este caso, se ajusta mejor al problema puesto que esta métrica es adecuada cuando se trabaja con un conjunto desbalanceado en lo que respecta a número de patrones de cada clase. De hecho, observando los datos numéricos, podemos destacar que los valores de AUC-PR son menores o incluso significativamente menores que los de AUC-ROC o de la sensibilidad, lo cual refleja la relevancia de utilizar esta métrica como referencia.\n",
    "\n",
    "Para entender la separación de los datos en el espacio, se utiliza primeramente como referencia al caso de utilizar una PCA que obtenga dos atributos. Se entrena el modelo y se observa cómo este es capaz de separar dichos datos, lo cual es observable en la imagen que se encuentra a continuación. Esta muestra que, en un espacio de dos dimensiones, los datos no son fácilmente separables, de lo cual se intuye que no se trata de un número muy adecuado de atributos.\n",
    "\n",
    "<img src=\"./images/values_2d_kNN.png\">\n",
    "\n",
    "En la imagen de abajo, se puede observar la comparativa entre los cuatro experimentos. Se trata de una gráfica donde se representa la media de las métricas seleccionadas y la desviación típica, de tal forma que la esquina superior izquierda representa el punto donde el clasificador obtiene una bondad máxima (ideal) para las métricas seleccionadas y, al mismo tiempo, donde dicho clasificador es más robusto (i.e. con una desviación típica pequeña, la variación de las métricas entre los N entrenamientos es muy pequeña y, por ello, el valor medio es más fiable). En el caso contrario, la esquina inferior derecha representa el extremo opuesto, teniendo en cuenta que la desviación típica es significativa (escasa robustez) y el valor medio de la métrica es muy bajo. Con respecto a la gráfica, los puntos simbolizan la precisión global y el resto de figuras representan los valores de AUC-PR para cada una de las clases. La finalidad de esta gráfica es simplemente estudiar a grandes rasgos cómo influye el número de atributos de entrada en los resultados y es por ello que no se hace énfasis en los valores concretos que se proporcionan para cada clase.  \n",
    "\n",
    "<img src=\"./images/kNN_edited.png\">\n",
    "\n",
    "### Máquina de soporte vectorial (SVM)\n",
    "\n",
    "Para este modelo, el kernel seleccionado es una función de base radial. Del mismo modo, como valor del parámetro C se escoge *C = 1.0*. Se realizan nuevamente los cuatro experimentos con PCA de 2, 3, 5 y 10 atributos, manteniendo constantes los dos parámetros anteriormente mencionados. Para este caso, se vuelve a utilizar el ejemplo con dos atributos observando las divisiones que realiza el modelo de aprendizaje. El primer aspecto a destacar es que, igualmente, la separación de las instancias en clases le resulta muy compleja. Por otra parte, se observan diferencias significativas entre como el algoritmo kNN y la máquina de soporte vectorial realizan dichas separaciones.\n",
    "\n",
    "<img src=\"./images/values_2d_svm.png\">\n",
    "\n",
    "En la imagen inferior, se pueden observar los resultados para este modelo de aprendizaje. Dichos resultados se interpretan del mismo modo que para el algoritmo kNN y se pueden concluir aspectos similares (un mayor número de atributos comporta una mejora de las métricas de evaluación en el punto de vista de su valor medio y una mayor robustez de los modelos entrenados). Destacar que los valores cuantitativos hacen referencia, de nuevo, a la precisión global y al valor de AUC-PR de cada clase. \n",
    "\n",
    "<img src=\"./images/SVM.png\">\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "El último de los modelos utilizados ha sido random forest. Como parámetros, en primer lugar se ajusta el número de árboles de decisión que constituyen el bosque a 100. Por otra parte, la máxima profundidad para la expansión de los nodos en los mismos es de 4. Las conclusiones extraídas, para este caso, son muy similares a las anteriores: mayor número de atributos implica modelos más precisos y robustos. Esto se puede observar en la imagen inferior, de nuevo mostrando las métricas de precisión global y de AUC-PR para cada clase.\n",
    "\n",
    "En este último caso, el modelo es aparentemente incapaz de separar de forma conveniente los datos para obtener valores aceptables, del mismo modo que en los dos casos anteriores. También se observan diferencias significativas en cómo el modelo realiza la división de dicho espacio bidimensional.\n",
    "\n",
    "<img src=\"./images/values_2d_rfor.png\">\n",
    "\n",
    "Cabe destacar que los entrenamientos de este tipo de modelos, para el problema aquí planteado, se muestran como los más pobres con respecto a la eficiencia en términos de tiempo, aunque continúan siendo tiempos muy aceptables.\n",
    "\n",
    "<img src=\"./images/RFOR.png\">\n",
    "\n",
    "## Comparación de los modelos\n",
    "\n",
    "- Una vez obtenidos los resultados para los tres tipos de modelos de aprendizaje empleados, buscando que todos ellos se puedan comparar en las mayores condiciones de igualdad posibles, se exponen conjuntamente en una cuarta gráfica. Para realizar esta comparación, se utilizan ya los resultados relativos únicamente a utilizar una PCA que obtenga 10 atributos a la salida, puesto que se considera como el mejor caso para los tres algoritmos. Las métricas utilizadas son, de nuevo, la precisión global y la AUC-PR por las mismas razones que se explican en apartados anteriores. \n",
    "\n",
    "- El primer detalle que se aprecia es que las métricas para el algoritmo kNN y para la máquina de soporte vectorial son muy parejos, donde el propio kNN parece ser ligeramente superior sobre todo en lo que respecta a la métrica de la precisión global.\n",
    "\n",
    "- Por otra parte, el random forest parece ofrecer una efectividad más pobre dado que no solo la precisión global es más baja, si no que también los valores de AUC-PR para cada clase también parecen serlo.\n",
    "\n",
    "Las comparaciones se pueden observar de forma visual en la imagen que se adjunta a continuación.\n",
    "\n",
    "<img src=\"./images/comparison.png\">\n",
    "\n",
    "- En la siguiente tabla, se observan los valores de precisión global para cada uno de los modelos utilizando una PCA que obtiene 10 atributos. Los datos se corresponden con lo mencionado anteriormente, es decir, el algoritmo kNN y la máquina de soporte vectorial (SVM) tienen una efectividad similar en lo que respecta a esta métrica pero, por su parte, el random forest es ligeramente peor (aunque sus valores son muy aceptables). Por otra parte, lo mismo se observa con la robustez de los modelos con respecto a esta métrica.\n",
    "\n",
    "|               |        Precisión       |\n",
    "|:-------------:|:----------------------:|\n",
    "| Algoritmo kNN | 99.1651% $\\pm$ 0.4864% |\n",
    "|      SVM      | 98.9533% $\\pm$ 0.5702% |\n",
    "| Random forest | 96.2150% $\\pm$ 1.3489% |\n",
    "\n",
    "- Por último, se hace lo mismo con los valores de AUC-PR. Se observa que se supera el 95% en todos los casos para el algoritmo kNN y SVM. Además, la desviación típica no supera el 3% en ningún caso. Por su parte, random forest está siempre en el rango 90%-95% y la desviación típica es incluso próxima al 5% en algunas clases.\n",
    "\n",
    "|     AUC-PR    |         Clase 1 (BRCA)     |         Clase 2 (KIRC)        |         Clase 3 (COAD)     |         Clase 4 (LUAD)        |         Clase 5 (PRAD)       |\n",
    "|:-------------:|:----------------------:|:----------------------:|:----------------------:|:----------------------:|:----------------------:|\n",
    "| Algoritmo kNN | 99.1000% $\\pm$ 1.2127% | 99.0921% $\\pm$ 0.7439% | 96.9458% $\\pm$ 2.6949% | 99.1105% $\\pm$ 0.7452% | 98.7622% $\\pm$ 1.1424% |\n",
    "|      SVM      | 98.2397% $\\pm$ 1.1324% | 97.6723% $\\pm$ 1.5262% | 96.0261% $\\pm$ 2.6794% | 99.4992% $\\pm$ 0.7597% | 98.0714% $\\pm$ 1.6709% |\n",
    "| Random forest | 90.1146% $\\pm$ 4.2933% | 90.1796% $\\pm$ 4.8721% | 90.9204% $\\pm$ 2.1594% | 93.3720% $\\pm$ 4.2046% | 94.9747% $\\pm$ 3.2151% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el presente documento se ha expuesto un trabajo donde se utilizan técnicas de aprendizaje máquina para resolver un problema de clasificación en un dominio biomédico, tomando como partida una base de datos que representa el producto del análisis en la expresión de más de 20000 genes, utilizando la plataforma Illumina HiSeq y gracias a la técnica de RNA-Seq. Después de la consecución de múltiples experimentos tomando como referencia diversos modelos de aprendizaje máquina, se pueden extraer una serie de conclusiones:\n",
    "\n",
    "- En primer lugar, la ingente cantidad de atributos de los que dispone cada una de las instancias (los más de 20000 genes) es inmanejable de forma manual. En estas circunstancias, el algoritmo de Principal Components Analysis o PCA se muestra como una de las aproximaciones más inmediatas e intuitivas de las que se dispone. A pesar de que los datos de salida no puedan ser comprendidos de forma intuitiva, ofrece grandes ventajas frente a otras estrategias como la de *features selection* o la de *features extraction*. \n",
    "\n",
    "- Por otra parte, cabe destacar la considerable cantidad de experimentos realizados, teniendo en cuenta que no solo se han utilizado tres modelos diferentes (algoritmo kNN, máquina de soporte vectorial y random forest) si no que además cada modelo ha sido probado con cuatro planteamientos diferentes: utilizando diferentes PCA que hayan obtenido, respectivamente, 2, 3, 5 y 10 atributos.\n",
    "\n",
    "- Es digno de mencionar la utilización de un splitting aleatorio, para dividir el conjunto de patrones de entrada entre entrenamiento y test y, con ello, la necesidad de ejecutar N entrenamientos para cada experimento concreto, computando la media y la desviación típica para esos N entrenamientos especificando así, no solo un valor representativo de cada métrica empleada, si no también clarificando numéricamente la robustez de cada uno de los modelos. \n",
    "\n",
    "- En cuanto a la efectividad de los modelos, cabe decir que se calculan varias métricas, tomando como referencia la precisión global y la del valor de AUC-PR concreto para cada clase. En primer lugar, la precisión global proporciona una visión de efectividad para el problema en su conjunto en lugar de considerar cada clase de forma independiente; por su parte, la AUC-PR es una métrica adecuada para los problemas donde exista un desbalanceo en el número de patrones para cada una de las diferentes clases. \n",
    "\n",
    "- Con respecto a los resultados, se demuestra que el número de atributos utilizados a la entrada de los modelos de aprendizaje es relevante e influye de manera importante en su efectividad y robustez, observándose que los datos resultantes de aplicar una PCA que reduce los originales a 10 atributos son los que mejor ajustan el problema tal y como se ha tratado y se documenta en este texto, frente a casos donde el número de atributos sea inferior (2, 3 y 5, concretamente).\n",
    "\n",
    "- Por su parte, en lo que se refiere a modelos de aprendizaje utilizados, la efectividad del algoritmo kNN es muy similar al de la máquina de soporte vectorial. En el polo opuesto se encuentra el random forest, el modelo que peores resultados ha mostrado que, aunque aceptables, son más pobres y los modelos obtenidos son menos robustos. \n",
    "\n",
    "- En general, se puede concluir que la forma de abordar el problema ha sido adecuada pero, como en cualquier trabajo de investigación, se pueden seguir tomando diversas líneas para evaluar el impacto de otros aspectos en los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo futuro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, tras la realización de los experimentos y la redacción de las principales conclusiones de los mismos, se pueden especificar algunas posibles líneas de expansión del presente trabajo en casos futuros.\n",
    "\n",
    "- En primer lugar, la utilización del algoritmo PCA obteniendo un número de atributos mayor que 10, para estudiar en qué momento se alcanza un número idóneo de estos.\n",
    "\n",
    "- Por otra parte, el planteamiento de un fine-tuning de los parámetros de los modelos utilizados.\n",
    "\n",
    "- Otra posible extensión del trabajo consiste en utilizar diferentes modelos de aprendizajes a los ya empleados, como puede ser el caso de redes de neuronas artificiales, contemplando incluso la posibilidad de recurrir a arquitecturas de redes profundas.\n",
    "\n",
    "- Del mismo modo, otra opción para línea futura supone aplicar técnicas como las de oversampling para resolver el problema del desequilibrio de patrones entre las diferentes clases que se mencionaba en apartados anteriores de este documento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
